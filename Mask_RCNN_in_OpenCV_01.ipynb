{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d9712aaf-e33e-46b8-b591-185c1f0853af",
   "metadata": {},
   "source": [
    "# Using Tensorflow Models in OpenCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7d2bed40-97c3-4254-818b-3dc4e3b45d39",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799d6406-2e3e-42cb-bc7b-d8cf26ad8c28",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36187882-dbb8-4296-834f-3c6aeb2c7b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "!cd model && wget http://download.tensorflow.org/models/object_detection/mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
    "!cd model && tar zxvf mask_rcnn_inception_v2_coco_2018_01_28.tar.gz\n",
    "!cd model && wget https://github.com/vjgpt/Object-Detection/raw/master/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt\n",
    "!cd model && wget https://github.com/vjgpt/Object-Detection/blob/master/mscoco_labels.names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef0da46-3e35-4240-9337-630759b519f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model configuration and weights\n",
    "cfg_path = './model/mask_rcnn_inception_v2_coco_2018_01_28.pbtxt'\n",
    "weight_path = './model/mask_rcnn_inception_v2_coco_2018_01_28/frozen_inference_graph.pb'\n",
    "classes_path = './model/mscoco_labels.names'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8ade7650-e083-4cd4-b57d-1489407d97f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(classes_path) as json_data:\n",
    "    data = json.load(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9de89ddd-b84b-4448-927d-31c0053cf8c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['person\\r', 'bicycle\\r', 'car\\r', 'motorcycle\\r', 'airplane\\r', 'bus\\r', 'train\\r', 'truck\\r', 'boat\\r', 'traffic light\\r', 'fire hydrant\\r', '\\r', 'stop sign\\r', 'parking meter\\r', 'bench\\r', 'bird\\r', 'cat\\r', 'dog\\r', 'horse\\r', 'sheep\\r', 'cow\\r', 'elephant\\r', 'bear\\r', 'zebra\\r', 'giraffe\\r', '\\r', 'backpack\\r', 'umbrella\\r', '\\r', '\\r', 'handbag\\r', 'tie\\r', 'suitcase\\r', 'frisbee\\r', 'skis\\r', 'snowboard\\r', 'sports ball\\r', 'kite\\r', 'baseball bat\\r', 'baseball glove\\r', 'skateboard\\r', 'surfboard\\r', 'tennis racket\\r', 'bottle\\r', '\\r', 'wine glass\\r', 'cup\\r', 'fork\\r', 'knife\\r', 'spoon\\r', 'bowl\\r', 'banana\\r', 'apple\\r', 'sandwich\\r', 'orange\\r', 'broccoli\\r', 'carrot\\r', 'hot dog\\r', 'pizza\\r', 'donut\\r', 'cake\\r', 'chair\\r', 'couch\\r', 'potted plant\\r', 'bed\\r', '\\r', 'dining table\\r', '\\r', '\\r', 'toilet\\r', '\\r', 'tv\\r', 'laptop\\r', 'mouse\\r', 'remote\\r', 'keyboard\\r', 'cell phone\\r', 'microwave\\r', 'oven\\r', 'toaster\\r', 'sink\\r', 'refrigerator\\r', '\\r', 'book\\r', 'clock\\r', 'vase\\r', 'scissors\\r', 'teddy bear\\r', 'hair drier\\r', 'toothbrush']\n"
     ]
    }
   ],
   "source": [
    "print(data['payload']['blob']['rawLines'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "5516a65a-b663-404b-aa27-8020f7de2cd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_names = data['payload']['blob']['rawLines']\n",
    "len(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff848b9-943c-4f0d-b98e-ffb9b6cbcc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = cv.dnn.readNetFromTensorflow(weight_path, cfg_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4a0fc56-a38c-4035-b8bc-1182441b6008",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3809df01-8481-4306-8568-d7ef45515346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load test image\n",
    "img_path = './assets/bus.jpg'\n",
    "img = cv.imread(img_path)\n",
    "height, width, channels = img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8cb4c5e-aa0e-401f-aa49-33d4bd141c00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e90c0a2-2f3f-4aad-a0d8-58d2e1951924",
   "metadata": {},
   "source": [
    "![Using Tensorflow Models in OpenCV](./assets/Semantic_Image_Segmentation_01.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb35aae-1374-40cd-974c-fb44c606a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = cv.dnn.blobFromImage(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc27d63-1997-46e6-b72c-b2f6b47e3ead",
   "metadata": {},
   "source": [
    "## Model Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e0cbf9-837b-4e1e-b9b2-b35062845e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_predictions(model, blob):\n",
    "    model.setInput(blob)\n",
    "    boxes, masks = model.forward(['detection_out_final', 'detection_masks'])\n",
    "    return boxes, masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde9de20-0968-473a-b10e-91858c8a8c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxes, masks = get_predictions(model, blob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f94745b-8462-4638-96ab-d1e2aaf351d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(boxes), len(masks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7e350b-b75c-40ee-beb6-c6f5c63ccdd2",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Prediction Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a59be8a-cb03-4a2d-946a-dee15168d8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(height, width, channels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f56e2b-3e5f-4877-8f1a-795e846566c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas = np.zeros((height, width, channels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329e8804-d560-4e6d-88ac-c09d2b4d3459",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(masks)):\n",
    "    bbox = boxes[0, 0 , j]\n",
    "    mask = masks[j]\n",
    "\n",
    "    print(bbox)\n",
    "\n",
    "    class_id = bbox[1]\n",
    "    score = bbox[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4dd58e44-d7da-401f-98b2-1f423d740dd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter 100 detections by adding a detection confidence threshold\n",
    "threshold = 0.5\n",
    "# generate random colours for each class\n",
    "colours = [(random.randint(0,255), random.randint(0,255), random.randint(0,255)) for j in range(len(class_names))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d28a3b-fe6c-4a04-b599-18299ba1d390",
   "metadata": {},
   "source": [
    "#### Bounding Boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4255befb-baa9-425f-912a-9281ff8b2e79",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in range(len(masks)):\n",
    "    bbox = boxes[0, 0 , j]\n",
    "    mask = masks[j]\n",
    "\n",
    "    class_label = bbox[1]\n",
    "    score = bbox[2]\n",
    "    \n",
    "    if score > threshold:\n",
    "        # debug\n",
    "        print(class_label)\n",
    "        print(score)\n",
    "        print(mask.shape)\n",
    "        print(bbox.shape)\n",
    "\n",
    "        # bbox corner positions in relative/normalized coordinates * img dimensions as int = pixel position\n",
    "        x1, y1, x2, y2 = int(bbox[3] * width), int(bbox[4] * height), int(bbox[5] * width), int(bbox[6] * height)\n",
    "\n",
    "        output = cv.rectangle(img, (x1, y1), (x2, y2), (0, 255, 0))\n",
    "        \n",
    "        plt.imshow(output)\n",
    "        \n",
    "        # only keep mask for detected class label\n",
    "        mask = mask[int(class_label)]\n",
    "\n",
    "# debug output e.g.\n",
    "# 2.0 => class label\n",
    "# 0.9532703 => prediction confidence\n",
    "# (90, 15, 15) => mask consists of 90 (1 for each class the model was trained with) 15(*image width)x15(*image height) squares\n",
    "# (7,) => bounding box is drawn with 7 corner points"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87bc848c-f85d-4328-8d11-1998261d7ebf",
   "metadata": {},
   "source": [
    "![Using Tensorflow Models in OpenCV](./assets/Semantic_Image_Segmentation_02.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf50378-d9f3-47eb-92d3-4a9d7ae7eccf",
   "metadata": {},
   "source": [
    "#### Segmentation Masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2eed08c6-20aa-4fc5-89a4-4f4e985bf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(masks)):\n",
    "    bbox = boxes[0, 0 , j]\n",
    "    score = bbox[2]\n",
    "    \n",
    "    if score > threshold:\n",
    "        class_label = bbox[1]\n",
    "        mask = masks[j]\n",
    "        \n",
    "        # bbox corner positions in relative/normalized coordinates * img dimensions as int = pixel position\n",
    "        x1, y1, x2, y2 = int(bbox[3] * width), int(bbox[4] * height), int(bbox[5] * width), int(bbox[6] * height)\n",
    "        \n",
    "        # only keep mask for detected class label\n",
    "        mask = mask[int(class_label)]\n",
    "        # de-normalize mask\n",
    "        mask = cv.resize(mask, (x2-x1, y2-y1))\n",
    "        # debug\n",
    "        # print(mask.shape)\n",
    "\n",
    "        _, mask = cv.threshold(mask, 0.5, 1, cv.THRESH_BINARY)\n",
    "        \n",
    "\n",
    "        for c in range (channels):\n",
    "            # multiply by 255 to get white masks for all classes\n",
    "            canvas[y1:y2, x1:x2, c] = mask * colours[int(class_label)][c]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f388814-1521-4e1d-9a51-6a2a55847393",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(canvas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33115b2-fc97-4504-a421-028337dba780",
   "metadata": {},
   "source": [
    "![Using Tensorflow Models in OpenCV](./assets/Semantic_Image_Segmentation_03.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "6f77c225-9f81-4bc9-87d7-0e11e9e966dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlay = ((0.8 * canvas) + (0.2 * img)).astype('uint8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b4da8d-9616-477c-9b56-df7886923ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(overlay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965c10b-9f0e-4c7d-b45c-a9fb23e00046",
   "metadata": {},
   "source": [
    "![Using Tensorflow Models in OpenCV](./assets/Semantic_Image_Segmentation_04.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9b06b9-d895-4321-b16d-1d3e338692df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
